# Deep neural networks explain spiking activity in auditory cortex

> ğŸ“˜ This is the **official implementation** for:  
> Bilal Ahmed et al., 2025
> [ğŸ“„ Read the paper](https://www.biorxiv.org/content/10.1101/2024.11.12.623280v1)

## Overview
This repository provides the code used to model and analyze spiking activity in the auditory cortex using deep neural networks...

![Schematic overview](./assets/schematic.png)

## ğŸ“‚ Dataset

The neural dataset used in this project is publicly available on Zenodo:  
ğŸ”— [Click here to access the dataset](https://doi.org/10.5281/zenodo.16175377)

> If you use this dataset, please make sure to cite it appropriately. See the [ğŸ”— Citation](#-citation) section below.


## ğŸ“‚ Repository Structure

The repository is organized as follows:

```
deep-auditory-spikes/
â”œâ”€â”€ auditory_cortex/             â† Core project code
â”‚   â”œâ”€â”€ dnn_feature_extractor/   â† Extracts features from pretrained DNNs
â”‚   â”œâ”€â”€ neural_data/             â† Loads and preprocesses neural recordings
â”‚   â”œâ”€â”€ plotters/                â† Plotting utilities
â”‚   â”œâ”€â”€ analyses/                â† Analysis and evaluation scripts
â”‚   â”œâ”€â”€ io_utils/                â† Handles caching, loading, and saving results
â”‚   â”œâ”€â”€ config.yml               â† Configuration for datasets, models, paths, etc.
â”‚   â”œâ”€â”€ dataloader.py            â† Loads DNN features and neural data
â”‚   â”œâ”€â”€ data_assembler.py        â† Prepares training and testing data
â”‚   â”œâ”€â”€ encoding.py              â† Fits temporal response functions (TRFs)
â”‚   â””â”€â”€ utils.py                 â† Miscellaneous utility functions
â”œâ”€â”€ docs/                        â† Documentation and references
â”œâ”€â”€ scripts/                     â† Experiment runner scripts
â”œâ”€â”€ notebooks/                   â† Interactive Jupyter notebooks for analysis
â””â”€â”€ README.md                    â† Project overview (this file)
```


## ğŸ› ï¸ Installation

This repository depends on the following external GitHub repositories. Please make sure to clone and install them manually:

- https://github.com/bilalhsp/Wav2Letter  
- https://github.com/jgmakin/utils_jgm.git  
- https://github.com/SeanNaren/deepspeech.pytorch.git  
- https://github.com/mcdermottLab/pycochleagram.git  

You can install each of them using the following commands:

```bash
git clone <repo_url>
cd <repo_folder>
pip install -e .
```

Once the dependencies are installed, clone and install this repository:

```bash
git clone https://github.com/bilalhsp/deep-auditory-spikes.git
cd deep-auditory-spikes
pip install -e .
```

## âš™ï¸ Configuration

Before running any scripts or experiments, make sure to edit the `config.yml` file:

```bash
auditory_cortex/config.yml
```

This file defines key paths and parameters. You must update the following fields to point to your local environment:

```yaml
neural_data_dir: /path/to/neural_data/
pretrained_models_dir: /path/to/pretrained_models/
results_dir: /path/to/save/results/
cache_dir: /path/to/feature/cache/
```

> âš ï¸ Make sure all the directories exist and are accessible before running the code.
> You can customize the provided file as needed.

## ğŸš€ Usage

The best way to get started is by exploring the example notebooks:

| Notebook | Description |
|----------|-------------|
| [`examples/1_neural_datasets.ipynb`](./examples/1_neural_datasets.ipynb) | Use neural dataset and metadata objects |
| [`examples/2_features_extractor.ipynb`](./examples/2_features_extractor.ipynb) | Use feature extractor objects to get DNN features |
| [`examples/3_dataloader.ipynb`](./examples/3_dataloader.ipynb) | Work with dataloader object (a unified interface to DNN features and neural data) |
| [`examples/4_data_assembler.ipynb`](./examples/4_data_assembler.ipynb) | Prepare training and test data |

> ğŸ’¡ **Tip**: Make sure to first configure your environment using the `config.yml` file as described above.


## ğŸ“Š Plotting Correlation Results

Download the precomputed correlation results archive:

[ğŸ“¦ Download ahmed-25-corr-results.tar.gz](https://github.com/bilalhsp/deep-auditory-spikes/releases/download/v1.0/ahmed-25-corr-results.tar.gz)

Then extract it inside your results directory (make sure this matches the `results_dir` path in your `config.yml`):

```bash
cd /path/to/your/results_dir
tar -xzf /path/to/ahmed-25-corr-results.tar.gz
```

This will create the `ahmed-25` subdirectory with the correlation results.

Finally, run the plotting notebooks located in the `notebooks/` directory to generate the figures from these results.

## ğŸ”— Citation

If you use this codebase or build on the methods in this project, please cite the following paper:

> **Ahmed, B. et al. (2025).**  
> *Deep Neural Networks Explain Spiking Activity in Auditory Cortex.*  
> _PLOS Computational Biology_ (In press).





